{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zMwREJ0RmKj5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import csv\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "from numpy import unique\n",
        "import torch.optim as optim\n",
        "from google.colab import drive\n",
        "from warnings import filterwarnings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjKpY-horOWd"
      },
      "source": [
        "# Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Zo08_1GKf6IR"
      },
      "outputs": [],
      "source": [
        "train_dataset = pd.read_csv('/content/drive/MyDrive/all_data.csv')\n",
        "test_dataset = pd.read_csv('/content/drive/MyDrive/wearable-data_100_f.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train = train_dataset.drop(columns=['label'])\n",
        "y_train = train_dataset['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
        "y_train = y_train.reshape((y_train.shape[0], y_train.shape[1], 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Bi-ZhJKneWIO"
      },
      "outputs": [],
      "source": [
        "X_train_tensor = torch.tensor(X_train)\n",
        "y_train_tensor = torch.tensor(y_train.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_test = test_dataset.drop(columns=['label'])\n",
        "y_test = test_dataset['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_meta, y_train_meta, X_test_meta, y_test_meta = train_test_split(\n",
        "    X_test, y_test, test_size=0.20, random_state=10, stratify=y_test, shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_meta_tensor = torch.tensor(X_train_meta, dtype=torch.float32)\n",
        "y_train_meta_tensor = torch.tensor(y_train_meta.values, dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "M3CswKmAsZ42"
      },
      "outputs": [],
      "source": [
        "X_test_meta_tensor = torch.tensor(X_test_meta,dtype=torch.float32)\n",
        "y_test_meta_tensor = torch.tensor(y_test_meta.values,dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wxwk8pOKPr8K"
      },
      "source": [
        "### MobileNETv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "FbweXYxPGsLK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class ConvNormActivation(torch.nn.Sequential):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels,\n",
        "        out_channels,\n",
        "        kernel_size = 3,\n",
        "        stride = 1,\n",
        "        padding = None,\n",
        "        groups = 1,\n",
        "        norm_layer = nn.BatchNorm1d,\n",
        "        activation_layer = torch.nn.ReLU,\n",
        "        dilation = 1,\n",
        "        inplace = True,\n",
        "        bias = None,\n",
        "        conv_layer = torch.nn.Conv1d,\n",
        "    ):\n",
        "\n",
        "        if padding is None:\n",
        "          #  if isinstance(kernel_size, int) and isinstance(dilation, int):\n",
        "          #       padding = (kernel_size - 1) // 2 * dilation\n",
        "          #   else:\n",
        "          #       _conv_dim = len(kernel_size) if isinstance(kernel_size, Sequence) else len(dilation)\n",
        "          #       kernel_size = _make_ntuple(kernel_size, _conv_dim)\n",
        "          #       dilation = _make_ntuple(dilation, _conv_dim)\n",
        "          #       padding = tuple((kernel_size[i] - 1) // 2 * dilation[i] for i in range(_conv_dim))\n",
        "          padding = (kernel_size - 1) // 2 * dilation\n",
        "        if bias is None:\n",
        "            bias = norm_layer is None\n",
        "\n",
        "        layers = [\n",
        "            conv_layer(\n",
        "                in_channels,\n",
        "                out_channels,\n",
        "                kernel_size,\n",
        "                stride,\n",
        "                padding,\n",
        "                dilation=dilation,\n",
        "                groups=groups,\n",
        "                bias=bias,\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        if norm_layer is not None:\n",
        "            layers.append(norm_layer(out_channels))\n",
        "\n",
        "        if activation_layer is not None:\n",
        "            params = {} if inplace is None else {\"inplace\": inplace}\n",
        "            layers.append(activation_layer(**params))\n",
        "        super().__init__(*layers)\n",
        "        #_log_api_usage_once(self)\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "        # if self.__class__ == ConvNormActivation:\n",
        "        #     warnings.warn(\n",
        "        #         \"Don't use ConvNormActivation directly, please use Conv2dNormActivation and Conv3dNormActivation instead.\"\n",
        "        #     )\n",
        "\n",
        "\n",
        "class Conv1dNormActivation(ConvNormActivation):\n",
        "    \"\"\"\n",
        "    Configurable block used for Convolution2d-Normalization-Activation blocks.\n",
        "\n",
        "    Args:\n",
        "        in_channels (int): Number of channels in the input image\n",
        "        out_channels (int): Number of channels produced by the Convolution-Normalization-Activation block\n",
        "        kernel_size: (int, optional): Size of the convolving kernel. Default: 3\n",
        "        stride (int, optional): Stride of the convolution. Default: 1\n",
        "        padding (int, tuple or str, optional): Padding added to all four sides of the input. Default: None, in which case it will be calculated as ``padding = (kernel_size - 1) // 2 * dilation``\n",
        "        groups (int, optional): Number of blocked connections from input channels to output channels. Default: 1\n",
        "        norm_layer (Callable[..., torch.nn.Module], optional): Norm layer that will be stacked on top of the convolution layer. If ``None`` this layer won't be used. Default: ``torch.nn.BatchNorm2d``\n",
        "        activation_layer (Callable[..., torch.nn.Module], optional): Activation function which will be stacked on top of the normalization layer (if not None), otherwise on top of the conv layer. If ``None`` this layer won't be used. Default: ``torch.nn.ReLU``\n",
        "        dilation (int): Spacing between kernel elements. Default: 1\n",
        "        inplace (bool): Parameter for the activation layer, which can optionally do the operation in-place. Default ``True``\n",
        "        bias (bool, optional): Whether to use bias in the convolution layer. By default, biases are included if ``norm_layer is None``.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels,\n",
        "        out_channels,\n",
        "        kernel_size = 3,\n",
        "        stride = 1,\n",
        "        padding = None,\n",
        "        groups = 1,\n",
        "        norm_layer = torch.nn.BatchNorm1d,\n",
        "        activation_layer = torch.nn.ReLU,\n",
        "        dilation = 1,\n",
        "        inplace = True,\n",
        "        bias = None,\n",
        "    ):\n",
        "\n",
        "        super().__init__(\n",
        "            in_channels,\n",
        "            out_channels,\n",
        "            kernel_size,\n",
        "            stride,\n",
        "            padding,\n",
        "            groups,\n",
        "            norm_layer,\n",
        "            activation_layer,\n",
        "            dilation,\n",
        "            inplace,\n",
        "            bias,\n",
        "            torch.nn.Conv1d,\n",
        "        )\n",
        "\n",
        "\n",
        "class InvertedResidual(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        inp,\n",
        "        oup,\n",
        "        stride,\n",
        "        expand_ratio,\n",
        "        norm_layer = None\n",
        "    ):\n",
        "\n",
        "        super().__init__()\n",
        "        self.stride = stride\n",
        "        # if stride not in [1, 2]:\n",
        "        #     raise ValueError(f\"stride should be 1 or 2 instead of {stride}\")\n",
        "\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm1d\n",
        "\n",
        "        hidden_dim = int(round(inp * expand_ratio))\n",
        "        self.use_res_connect = self.stride == 1 and inp == oup\n",
        "\n",
        "        layers = []\n",
        "        if expand_ratio != 1:\n",
        "            # pw\n",
        "            layers.append(\n",
        "                Conv1dNormActivation(inp,\n",
        "                                     hidden_dim,\n",
        "                                     kernel_size = 1,\n",
        "                                     norm_layer=norm_layer,\n",
        "                                     activation_layer=nn.ReLU6)\n",
        "            )\n",
        "        layers.extend(\n",
        "            [\n",
        "                # dw\n",
        "                Conv1dNormActivation(\n",
        "                    hidden_dim,\n",
        "                    hidden_dim,\n",
        "                    stride=stride,\n",
        "                    groups=hidden_dim,\n",
        "                    norm_layer=norm_layer,\n",
        "                    activation_layer=nn.ReLU6,\n",
        "                ),\n",
        "                # pw-linear\n",
        "                nn.Conv1d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
        "                norm_layer(oup),\n",
        "            ]\n",
        "        )\n",
        "        self.conv = nn.Sequential(*layers)\n",
        "        self.out_channels = oup\n",
        "        self._is_cn = stride > 1\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.use_res_connect:\n",
        "            return x + self.conv(x)\n",
        "        else:\n",
        "            return self.conv(x)\n",
        "\n",
        "\n",
        "def _make_divisible(v, divisor, min_value=None):\n",
        "    \"\"\"\n",
        "    This function is taken from the original tf repo.\n",
        "    It ensures that all layers have a channel number that is divisible by 8\n",
        "    It can be seen here:\n",
        "    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n",
        "    :param v:\n",
        "    :param divisor:\n",
        "    :param min_value:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    if min_value is None:\n",
        "        min_value = divisor\n",
        "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
        "    # Make sure that round down does not go down by more than 10%.\n",
        "    if new_v < 0.9 * v:\n",
        "        new_v += divisor\n",
        "    return new_v\n",
        "\n",
        "\n",
        "class MobileNetV2(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_classes = 128,\n",
        "        input_length = 1000,\n",
        "        width_mult = 1.0,\n",
        "        inverted_residual_setting = None,\n",
        "        round_nearest = 8,\n",
        "        block = None,\n",
        "        norm_layer = None,\n",
        "        dropout = 0.2,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        MobileNet V2 main class\n",
        "\n",
        "        Args:\n",
        "            num_classes (int): Number of classes\n",
        "            width_mult (float): Width multiplier - adjusts number of channels in each layer by this amount\n",
        "            inverted_residual_setting: Network structure\n",
        "            round_nearest (int): Round the number of channels in each layer to be a multiple of this number\n",
        "            Set to 1 to turn off rounding\n",
        "            block: Module specifying inverted residual building block for mobilenet\n",
        "            norm_layer: Module specifying the normalization layer to use\n",
        "            dropout (float): The droupout probability\n",
        "\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        #_log_api_usage_once(self)\n",
        "\n",
        "        if block is None:\n",
        "            block = InvertedResidual\n",
        "\n",
        "        if norm_layer is None:\n",
        "            norm_layer = nn.BatchNorm1d\n",
        "\n",
        "        image_channel = 1\n",
        "        input_channel = 32\n",
        "        last_channel = 128\n",
        "        self.input_length = input_length\n",
        "\n",
        "        if inverted_residual_setting is None:\n",
        "            inverted_residual_setting = [\n",
        "                # t, c, n, s\n",
        "                [1, 16, 1, 1],\n",
        "                [6, 24, 2, 2],\n",
        "                [6, 32, 3, 2],\n",
        "                [6, 64, 4, 2],\n",
        "                [6, 128, 3, 1]\n",
        "                # [6, 160, 3, 2],\n",
        "                # [6, 320, 1, 1],\n",
        "            ]\n",
        "\n",
        "        # only check the first element, assuming user knows t,c,n,s are required\n",
        "        if len(inverted_residual_setting) == 0 or len(inverted_residual_setting[0]) != 4:\n",
        "            raise ValueError(\n",
        "                f\"inverted_residual_setting should be non-empty or a 4-element list, got {inverted_residual_setting}\"\n",
        "            )\n",
        "\n",
        "        # building first layer\n",
        "        input_channel = _make_divisible(input_channel * width_mult, round_nearest)\n",
        "        self.last_channel = _make_divisible(last_channel * max(1.0, width_mult), round_nearest)\n",
        "        features = [\n",
        "            Conv1dNormActivation(image_channel,\n",
        "                                 input_channel,\n",
        "                                 stride= 2,\n",
        "                                 norm_layer=norm_layer,\n",
        "                                 activation_layer=nn.ReLU6)\n",
        "        ]\n",
        "\n",
        "        # building inverted residual blocks\n",
        "        for t, c, n, s in inverted_residual_setting:\n",
        "            output_channel = _make_divisible(c * width_mult, round_nearest)\n",
        "            for i in range(n):\n",
        "                stride = s if i == 0 else 1\n",
        "                features.append(block(input_channel,\n",
        "                                      output_channel,\n",
        "                                      stride,\n",
        "                                      expand_ratio=t,\n",
        "                                      norm_layer=norm_layer))\n",
        "                input_channel = output_channel\n",
        "\n",
        "        # building last several layers\n",
        "        features.append(\n",
        "            Conv1dNormActivation(\n",
        "                input_channel,\n",
        "                self.last_channel,\n",
        "                kernel_size= 1,\n",
        "                norm_layer=norm_layer,\n",
        "                activation_layer=nn.ReLU6\n",
        "            )\n",
        "        )\n",
        "        # make it nn.Sequential\n",
        "        self.features = nn.Sequential(*features)\n",
        "\n",
        "        # building classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(p=dropout),\n",
        "            nn.Linear(self.last_channel, num_classes),\n",
        "        )\n",
        "\n",
        "        # weight initialization\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv1d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\")\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, (nn.BatchNorm1d, nn.GroupNorm)):\n",
        "                nn.init.ones_(m.weight)\n",
        "                nn.init.zeros_(m.bias)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.zeros_(m.bias)\n",
        "\n",
        "    def _forward_impl(self, x):\n",
        "        # This exists since TorchScript doesn't support inheritance, so the superclass method\n",
        "        # (this one) needs to have a name other than `forward` that can be accessed in a subclass\n",
        "        x = self.features(x)\n",
        "        # Cannot use \"squeeze\" as batch-size can be 1\n",
        "        x = nn.functional.adaptive_avg_pool1d(x, 1)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.reshape(x, (-1, 1, self.input_length))\n",
        "        return self._forward_impl(x)\n",
        "\n",
        "\n",
        "model_mobilenet = MobileNetV2()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "a0gxyjjtjqe_"
      },
      "outputs": [],
      "source": [
        "def df_class(X, Y, n):\n",
        "    class_list = []\n",
        "    for i in range(n):\n",
        "        class_mask = Y == i\n",
        "        df_i_label = X[class_mask]\n",
        "        class_list.append(df_i_label)\n",
        "    return class_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "5fzPHMCsjqcY"
      },
      "outputs": [],
      "source": [
        "train_class = df_class(X_train_tensor, y_train_tensor, 4)\n",
        "\n",
        "train_class_indices = [0, 1, 2,3]\n",
        "train_patches_class = [train_class[i] for i in train_class_indices]\n",
        "train_class_labels = [0, 1, 2,3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "rseVV9kJ7Lle"
      },
      "outputs": [],
      "source": [
        "test_class_1= df_class(X_train_meta_tensor,y_train_meta_tensor,2)\n",
        "test_class_2 = df_class(X_test_meta_tensor,y_test_meta_tensor,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "DqUAOa8_jqY_"
      },
      "outputs": [],
      "source": [
        "test_class_indices = [0,1]\n",
        "test_class_labels = [0,1]\n",
        "\n",
        "test_patches_class_1 = [test_class_1[i] for i in test_class_indices]\n",
        "test_patches_class_2 = [test_class_2[i] for i in test_class_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "THCJv3XisnFv"
      },
      "outputs": [],
      "source": [
        "def calc_euclidean_dists(x, y):\n",
        "    n = x.size(0)\n",
        "    m = y.size(0)\n",
        "\n",
        "    x = x.unsqueeze(1).expand(n, m, -1)\n",
        "    y = y.unsqueeze(0).expand(n, m, -1)\n",
        "\n",
        "    return torch.mean(torch.pow(x - y, 2), dim=2)\n",
        "\n",
        "def calc_std_predictions(mc_predictions):\n",
        "    mc_predictions_tensor = torch.stack(mc_predictions, dim=0)\n",
        "    std_predictions = torch.std(mc_predictions_tensor, dim=0)\n",
        "\n",
        "    return std_predictions\n",
        "\n",
        "def calc_mean_accuracy(predictions, y):\n",
        "\n",
        "    accuracy = torch.mean((torch.argmax(predictions, dim=-1) == torch.argmax(y, dim=-1)).float())\n",
        "\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUGSHI0r1n6G"
      },
      "source": [
        "### Protomodel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "dYlMytM8sPEA"
      },
      "outputs": [],
      "source": [
        "mc_loss_weight = 0.5\n",
        "n_times = 10\n",
        "class Prototypical(nn.Module):\n",
        "    def __init__(self, model_mobilenet, d):\n",
        "        super(Prototypical, self).__init__()\n",
        "        self.d = d\n",
        "        self.encoder = model_mobilenet\n",
        "\n",
        "    def forward(self, support, query, support_labels, query_labels, K, C, N, n_times, training):\n",
        "        n_class = C\n",
        "        n_support = K\n",
        "        n_query = N\n",
        "        tC = 2\n",
        "        n_times = 10\n",
        "\n",
        "        if training == True :\n",
        "            loss = 0\n",
        "            mc_predictions = []\n",
        "            for i in range(n_times) :                                               # n_times passing every query sample for calculating variance\n",
        "\n",
        "                y = torch.zeros((int(C*N),C))\n",
        "                for i in range(int(C*N)):\n",
        "                    x = (support_labels == query_labels[i]).nonzero(as_tuple=True)[0]                        # creation of 1-hot for true labels\n",
        "                    y[i][x] = 1.\n",
        "                cat = torch.cat([support,query], axis=0)\n",
        "                z = self.encoder(cat)\n",
        "                #print(z)\n",
        "                z_prototypes = z[:n_class * n_support].view(n_class, n_support, z.shape[-1])\n",
        "                z_prototypes = torch.mean(z_prototypes, dim=1)\n",
        "                z_query = z[n_class * n_support:]\n",
        "                dists = calc_euclidean_dists(z_query, z_prototypes)\n",
        "\n",
        "                log_p_y = torch.nn.functional.log_softmax(-dists, dim=-1)\n",
        "                #print(log_p_y)\n",
        "                # y_tensor = torch.from_numpy(y)\n",
        "                # loss1 = -torch.mean(torch.sum(y_tensor * log_p_y, dim=-1))\n",
        "                y = y.cuda()\n",
        "                loss1  = -torch.mean(torch.sum(y * log_p_y, dim=-1))\n",
        "                loss += loss1\n",
        "                predictions = torch.nn.functional.softmax(-dists, dim=-1)\n",
        "                mc_predictions.append(predictions)\n",
        "\n",
        "            mc_predictions = torch.stack(mc_predictions, axis =0)\n",
        "            std_predictions = torch.std(mc_predictions, axis = 0)\n",
        "            mean_predictions = torch.mean(mc_predictions, axis =0)\n",
        "            std = torch.sum(torch.sum(std_predictions * y,axis=1))\n",
        "\n",
        "            # Calculate the loss and accuracy\n",
        "            loss += mc_loss_weight*std\n",
        "            #print(loss)\n",
        "            mean_accuracy = calc_mean_accuracy(mean_predictions,y)\n",
        "\n",
        "            return loss, mean_accuracy, mean_predictions\n",
        "\n",
        "        if training == False:\n",
        "          loss = 0\n",
        "          mc_predictions = []\n",
        "          for i in range(n_times):\n",
        "            y = torch.zeros((int(C*N), C))\n",
        "            for i in range(int(C*N)):\n",
        "              #x = support_labels.index(query_labels[i])\n",
        "              x = (support_labels == query_labels[i]).nonzero(as_tuple=True)[0]\n",
        "              y[i][x] = 1.\n",
        "\n",
        "            cat = torch.cat([support, query], dim=0)\n",
        "            z = self.encoder(cat)\n",
        "            z_prototypes = z[:n_class * n_support].view(n_class, n_support, z.shape[-1])\n",
        "            z_prototypes = torch.mean(z_prototypes, dim=1)\n",
        "            z_query = z[n_class * n_support:]\n",
        "            #print('z_prototypes 0',z_prototypes[0])\n",
        "            #print('z_prototypes 1',z_prototypes[1])\n",
        "            dists = calc_euclidean_dists(z_query, z_prototypes)\n",
        "           # print('dist 0',dists[0])\n",
        "           # print('dist 1',dists[1])\n",
        "            log_p_y = torch.nn.functional.log_softmax(-dists, dim=-1)\n",
        "            # print('log_p_y 0',log_p_y[0])\n",
        "            # print('log_p_y 1',log_p_y[1])\n",
        "            #y = y.cuda()\n",
        "            loss1 = -torch.mean(torch.sum(log_p_y * y, dim=-1))\n",
        "            loss += loss1\n",
        "            predictions = torch.nn.functional.softmax(-dists, dim=-1)\n",
        "            # print('predictions 0',predictions[0])\n",
        "            # print('predictions 1',predictions[1])\n",
        "            mc_predictions.append(predictions)\n",
        "            #print('mc_predictions ',mc_predictions)\n",
        "\n",
        "          classwise_mean_acc = []\n",
        "          mc_predictions = torch.stack(mc_predictions, axis =0)\n",
        "          mean_predictions = torch.mean(mc_predictions, axis=0)\n",
        "\n",
        "\n",
        "          mean_eq = torch.tensor(torch.argmax(mean_predictions, dim=-1).int() == torch.argmax(y, dim=-1).int(), dtype=torch.float32)\n",
        "          mean_accuracy = torch.mean(mean_eq)\n",
        "          mean_pred_index = torch.argmax(mean_predictions, dim=1)\n",
        "    # Mean class-wise accuracies\n",
        "          mean_correct_class = [[] for _ in range(tC)]\n",
        "          mean_correct_pred = [[] for _ in range(tC)]\n",
        "          classwise_mean_acc = [[] for _ in range(tC)]\n",
        "\n",
        "          for i in range(int(C * N)):\n",
        "              #x = support_labels.index(query_labels[i])\n",
        "              x = (support_labels == query_labels[i]).nonzero(as_tuple=True)[0]\n",
        "              mean_correct_class[x].append('4')\n",
        "\n",
        "              if mean_pred_index[i] == x:\n",
        "                  mean_correct_pred[x].append('4')\n",
        "\n",
        "          for i in range(tC):\n",
        "              z = len(mean_correct_pred[i]) / len(mean_correct_class[i])\n",
        "              classwise_mean_acc[i].append(z)\n",
        "\n",
        "          # Standard deviation calculation\n",
        "          # std = 0\n",
        "          # for i in range(int(C * N)):\n",
        "          #    # x = support_labels.index(query_labels[i])\n",
        "          #     x = (support_labels == query_labels[i]).nonzero(as_tuple=True)[0]\n",
        "          #     p_i = torch.stack([p[i, :] for p in mc_predictions])\n",
        "          #     std_i = torch.std(p_i, dim=0)\n",
        "          #     std_i_true = std_i[x]\n",
        "          #     std += std_i_true\n",
        "\n",
        "          # loss += mc_loss_weight * std\n",
        "\n",
        "          # y = torch.zeros((int(C * N), C))\n",
        "          # for i in range(int(C * N)):\n",
        "          #     x = (support_labels == query_labels[i]).nonzero(as_tuple=True)[0]\n",
        "          #     #x = support_labels.index(query_labels[i])\n",
        "          #     y[i][x] = 1.\n",
        "\n",
        "        return  mc_predictions, mean_accuracy, y\n",
        "          #return  mc_predictions\n",
        "\n",
        "\n",
        "    def save(self, model_path):\n",
        "      torch.save(self.encoder.state_dict(), model_path)\n",
        "\n",
        "    def load(self, model_path):\n",
        "      self.encoder.load_state_dict(torch.load(model_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "nR3TKPB1IuLX"
      },
      "outputs": [],
      "source": [
        "ProtoModel = Prototypical(model_mobilenet, 1000)\n",
        "ProtoModel.cuda()\n",
        "n_times = 10\n",
        "optimizer = optim.Adam(ProtoModel.parameters(), lr=0.001)\n",
        "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsvKNBBdY1_M"
      },
      "source": [
        "# Train Base learner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "pOPNrsqcideU"
      },
      "outputs": [],
      "source": [
        "def train_episode(df_list, K, C, N, class_labels):\n",
        "    selected_classes = np.random.choice(class_labels, C, replace=False)\n",
        "    support_list = []\n",
        "    query_list = []\n",
        "    query_labels = []\n",
        "    support_labels = torch.tensor(selected_classes)\n",
        "\n",
        "    for x in selected_classes:\n",
        "        df_indices = np.random.choice(len(df_list[x - 1]), K, replace=False)\n",
        "        support_ = df_list[x - 1][df_indices, :]\n",
        "        qran_indices = np.random.choice(len(df_list[x - 1]), N, replace=False)\n",
        "        query_ = df_list[x - 1][qran_indices, :]\n",
        "\n",
        "        for i in range(N):\n",
        "            query_labels.append(x)\n",
        "        query_list.extend(query_)\n",
        "        support_list.extend(support_)\n",
        "\n",
        "    temp1 = list(zip(query_list, query_labels))\n",
        "    random.shuffle(temp1)\n",
        "    query_list, query_labels = zip(*temp1)\n",
        "\n",
        "    query_list = torch.reshape(torch.cat(query_list), (C * N, 1000))\n",
        "    support_list = torch.reshape(torch.cat(support_list), (C * K, 1000))\n",
        "    support_list = support_list.unsqueeze(-1)\n",
        "    query_list = query_list.unsqueeze(-1)\n",
        "    query_labels = torch.tensor(query_labels)\n",
        "    # print('support shape:',support_list.shape )\n",
        "    # print('query shape:',query_list.shape )\n",
        "    return query_list, support_list, query_labels, support_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iu_5YNQl5c_2"
      },
      "source": [
        "### with GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "mdqYFmoGO9yX"
      },
      "outputs": [],
      "source": [
        "def train_step(support, query, support_labels, query_labels, K, C, N, training=True):\n",
        "    #support = torch.cat(support, 0)\n",
        "    #query = torch.cat(query,0)\n",
        "    support = support.cuda().float()\n",
        "    query = query.cuda().float()\n",
        "    support_labels = support_labels.cuda().float()\n",
        "    query_labels = query_labels.cuda().float()\n",
        "    loss, mean_accuracy, mean_predictions = ProtoModel(support, query, support_labels, query_labels, K, C, N, n_times, training=True)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item(), mean_accuracy.item(), mean_predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2KWhktf5fvw"
      },
      "source": [
        "### with CPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "4D0L79BH5WPm"
      },
      "outputs": [],
      "source": [
        "def train_step(support, query, support_labels, query_labels, K, C, N, training=True):\n",
        "    loss, mean_accuracy, mean_predictions = ProtoModel(support, query, support_labels, query_labels, K, C, N, n_times, training=True)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item(), mean_accuracy.item(), mean_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "hnJXEJ7ycfp6"
      },
      "outputs": [],
      "source": [
        "checkpoint_dir = '/content/drive/MyDrive/Model-checkpoints/train/'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfjU8z6w5iBG"
      },
      "source": [
        "### train loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "LxXpvRhKOyi2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Train Loss: 10.99, Train Accuracy: 36.04\n",
            "Epoch 2, Train Loss: 10.55, Train Accuracy: 45.27\n",
            "Epoch 3, Train Loss: 9.05, Train Accuracy: 57.00\n",
            "Epoch 4, Train Loss: 8.50, Train Accuracy: 61.20\n",
            "Epoch 5, Train Loss: 8.16, Train Accuracy: 64.33\n",
            "Epoch 6, Train Loss: 7.93, Train Accuracy: 65.36\n",
            "Epoch 7, Train Loss: 7.73, Train Accuracy: 67.02\n",
            "Epoch 8, Train Loss: 7.78, Train Accuracy: 66.78\n",
            "Epoch 9, Train Loss: 7.63, Train Accuracy: 66.87\n",
            "Epoch 10, Train Loss: 7.38, Train Accuracy: 69.16\n",
            "Epoch 11, Train Loss: 7.05, Train Accuracy: 70.84\n",
            "Epoch 12, Train Loss: 7.03, Train Accuracy: 71.07\n",
            "Epoch 13, Train Loss: 6.96, Train Accuracy: 70.71\n",
            "Epoch 14, Train Loss: 6.89, Train Accuracy: 71.20\n",
            "Epoch 15, Train Loss: 6.97, Train Accuracy: 71.62\n",
            "Epoch 16, Train Loss: 6.77, Train Accuracy: 73.22\n",
            "Epoch 17, Train Loss: 6.70, Train Accuracy: 73.69\n",
            "Epoch 18, Train Loss: 6.66, Train Accuracy: 74.27\n",
            "Epoch 19, Train Loss: 6.50, Train Accuracy: 74.38\n",
            "Epoch 20, Train Loss: 6.45, Train Accuracy: 73.67\n",
            "Epoch 21, Train Loss: 6.33, Train Accuracy: 75.87\n",
            "Epoch 22, Train Loss: 6.23, Train Accuracy: 76.18\n",
            "Epoch 23, Train Loss: 6.16, Train Accuracy: 77.33\n",
            "Epoch 24, Train Loss: 6.12, Train Accuracy: 76.00\n",
            "Epoch 25, Train Loss: 6.04, Train Accuracy: 77.40\n",
            "Epoch 26, Train Loss: 5.99, Train Accuracy: 78.09\n",
            "Epoch 27, Train Loss: 5.89, Train Accuracy: 77.60\n",
            "Epoch 28, Train Loss: 5.72, Train Accuracy: 78.71\n",
            "Epoch 29, Train Loss: 5.75, Train Accuracy: 79.00\n",
            "Epoch 30, Train Loss: 5.45, Train Accuracy: 79.44\n",
            "Epoch 31, Train Loss: 5.50, Train Accuracy: 80.27\n",
            "Epoch 32, Train Loss: 5.39, Train Accuracy: 81.20\n",
            "Epoch 33, Train Loss: 5.38, Train Accuracy: 80.56\n",
            "Epoch 34, Train Loss: 5.16, Train Accuracy: 82.27\n",
            "Epoch 35, Train Loss: 5.32, Train Accuracy: 81.13\n",
            "Epoch 36, Train Loss: 5.03, Train Accuracy: 82.47\n",
            "Epoch 37, Train Loss: 5.00, Train Accuracy: 82.80\n",
            "Epoch 38, Train Loss: 4.80, Train Accuracy: 83.29\n",
            "Epoch 39, Train Loss: 5.04, Train Accuracy: 82.24\n",
            "Epoch 40, Train Loss: 4.82, Train Accuracy: 83.58\n",
            "Epoch 41, Train Loss: 4.54, Train Accuracy: 85.38\n",
            "Epoch 42, Train Loss: 4.55, Train Accuracy: 85.33\n",
            "Epoch 43, Train Loss: 4.62, Train Accuracy: 84.91\n",
            "Epoch 44, Train Loss: 4.51, Train Accuracy: 85.24\n",
            "Epoch 45, Train Loss: 4.32, Train Accuracy: 86.73\n",
            "Epoch 46, Train Loss: 4.41, Train Accuracy: 85.78\n",
            "Epoch 47, Train Loss: 4.39, Train Accuracy: 85.84\n",
            "Epoch 48, Train Loss: 4.16, Train Accuracy: 86.60\n",
            "Epoch 49, Train Loss: 4.37, Train Accuracy: 85.84\n",
            "Epoch 50, Train Loss: 4.01, Train Accuracy: 87.04\n",
            "Epoch 51, Train Loss: 3.79, Train Accuracy: 88.67\n",
            "Epoch 52, Train Loss: 3.96, Train Accuracy: 87.44\n",
            "Epoch 53, Train Loss: 3.88, Train Accuracy: 87.98\n",
            "Epoch 54, Train Loss: 3.68, Train Accuracy: 88.67\n",
            "Epoch 55, Train Loss: 3.81, Train Accuracy: 88.42\n",
            "Epoch 56, Train Loss: 3.79, Train Accuracy: 88.36\n",
            "Epoch 57, Train Loss: 3.76, Train Accuracy: 88.31\n",
            "Epoch 58, Train Loss: 3.94, Train Accuracy: 87.96\n",
            "Epoch 59, Train Loss: 3.53, Train Accuracy: 90.11\n",
            "Epoch 60, Train Loss: 3.73, Train Accuracy: 88.87\n",
            "Epoch 61, Train Loss: 3.66, Train Accuracy: 89.33\n",
            "Epoch 62, Train Loss: 3.66, Train Accuracy: 89.24\n",
            "Epoch 63, Train Loss: 3.32, Train Accuracy: 90.47\n",
            "Epoch 64, Train Loss: 3.29, Train Accuracy: 90.29\n",
            "Epoch 65, Train Loss: 3.50, Train Accuracy: 89.80\n",
            "Epoch 66, Train Loss: 3.77, Train Accuracy: 88.76\n",
            "Epoch 67, Train Loss: 3.32, Train Accuracy: 90.42\n",
            "Epoch 68, Train Loss: 3.33, Train Accuracy: 90.56\n",
            "Epoch 69, Train Loss: 3.34, Train Accuracy: 90.53\n",
            "Epoch 70, Train Loss: 3.20, Train Accuracy: 90.93\n",
            "Epoch 71, Train Loss: 3.19, Train Accuracy: 90.71\n",
            "Epoch 72, Train Loss: 3.15, Train Accuracy: 90.89\n",
            "Epoch 73, Train Loss: 2.93, Train Accuracy: 91.33\n",
            "Epoch 74, Train Loss: 3.14, Train Accuracy: 91.18\n",
            "Epoch 75, Train Loss: 3.17, Train Accuracy: 91.20\n",
            "Epoch 76, Train Loss: 2.97, Train Accuracy: 91.93\n",
            "Epoch 77, Train Loss: 2.99, Train Accuracy: 91.38\n",
            "Epoch 78, Train Loss: 2.82, Train Accuracy: 92.07\n",
            "Epoch 79, Train Loss: 2.86, Train Accuracy: 92.02\n",
            "Epoch 80, Train Loss: 2.86, Train Accuracy: 92.13\n",
            "Epoch 81, Train Loss: 2.74, Train Accuracy: 92.64\n",
            "Epoch 82, Train Loss: 2.64, Train Accuracy: 92.96\n",
            "Epoch 83, Train Loss: 2.64, Train Accuracy: 92.87\n",
            "Epoch 84, Train Loss: 2.89, Train Accuracy: 91.84\n",
            "Epoch 85, Train Loss: 2.67, Train Accuracy: 92.51\n",
            "Epoch 86, Train Loss: 2.91, Train Accuracy: 92.40\n",
            "Epoch 87, Train Loss: 2.62, Train Accuracy: 93.11\n",
            "Epoch 88, Train Loss: 2.33, Train Accuracy: 93.96\n",
            "Epoch 89, Train Loss: 2.57, Train Accuracy: 93.67\n",
            "Epoch 90, Train Loss: 2.17, Train Accuracy: 94.51\n",
            "Epoch 91, Train Loss: 2.28, Train Accuracy: 94.09\n",
            "Epoch 92, Train Loss: 2.42, Train Accuracy: 93.58\n",
            "Epoch 93, Train Loss: 2.43, Train Accuracy: 93.24\n",
            "Epoch 94, Train Loss: 2.34, Train Accuracy: 93.67\n",
            "Epoch 95, Train Loss: 2.78, Train Accuracy: 92.13\n",
            "Epoch 96, Train Loss: 2.17, Train Accuracy: 94.36\n",
            "Epoch 97, Train Loss: 2.23, Train Accuracy: 94.53\n",
            "Epoch 98, Train Loss: 2.33, Train Accuracy: 93.91\n",
            "Epoch 99, Train Loss: 2.17, Train Accuracy: 94.56\n",
            "Epoch 100, Train Loss: 2.12, Train Accuracy: 94.71\n"
          ]
        }
      ],
      "source": [
        "K1 = 10      #support\n",
        "C = 4      #Class\n",
        "N = 15      # query\n",
        "n_episodes = 100\n",
        "\n",
        "for epoch in range(100):\n",
        "    train_loss = 0.0\n",
        "    train_acc = 0.0\n",
        "    for epi in range(n_episodes):\n",
        "        tquery_list, tsupport_list, query_labels, support_labels = train_episode(train_class, K1, C, N, train_class_labels)\n",
        "\n",
        "        train_loss_temp , temp_acc , c = train_step(tsupport_list, tquery_list, support_labels, query_labels, K1, C, N)\n",
        "        train_loss += train_loss_temp\n",
        "        train_acc += temp_acc\n",
        "    # Print the training loss and accuracy\n",
        "    print('Epoch {}, Train Loss: {:.2f}, Train Accuracy: {:.2f}'.format(epoch + 1, train_loss/n_episodes, train_acc/n_episodes * 100))\n",
        "\n",
        "    # if (epoch + 1) % 2 == 0:\n",
        "    #  torch.save(ProtoModel.state_dict(), f\"{checkpoint_prefix}_epoch_{epoch + 1}.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "25tqZXB-IzzU"
      },
      "outputs": [],
      "source": [
        "torch.save(ProtoModel.state_dict(), \"/content/drive/MyDrive/all_train_weights.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gX5rw6jy1n6J"
      },
      "source": [
        "### Load weights from training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "uLhcVJKb1MKO"
      },
      "outputs": [],
      "source": [
        "loaded_checkpoint = torch.load(\"C:/Users/tousi.KCRND/Desktop/all_train_weights.pth\", map_location=torch.device('cpu'))\n",
        "\n",
        "ProtoModel.load_state_dict(loaded_checkpoint)\n",
        "ProtoModel.cuda()\n",
        "\n",
        "optimizer = optim.Adam(ProtoModel.parameters(), lr=0.001)\n",
        "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
        "n_times = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5RB_xv8hZCt"
      },
      "source": [
        "# Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "kBxDB-CEhnhJ"
      },
      "outputs": [],
      "source": [
        "def tune_episode(patches_list, K, C, N, class_labels):\n",
        "    selected_classes = np.random.choice(class_labels, C, replace=False)\n",
        "    tsupport_patches = []\n",
        "    tquery_patches = []\n",
        "    query_labels = []\n",
        "    support_labels = torch.tensor(selected_classes)\n",
        "    #print(selected_classes)\n",
        "    for x in selected_classes:\n",
        "        sran_indices = np.random.choice(len(patches_list[x - 1]), K, replace=False)\n",
        "        #print('1')\n",
        "        support_patches = patches_list[x - 1][sran_indices, :]\n",
        "        qran_indices = np.random.choice(len(patches_list[x - 1]), N, replace=False)\n",
        "        query_patches = patches_list[x - 1][qran_indices, :]\n",
        "        #print('2')\n",
        "        for i in range(N):\n",
        "            query_labels.append(x)\n",
        "        tquery_patches.extend(query_patches)\n",
        "        tsupport_patches.extend(support_patches)\n",
        "\n",
        "    #tquery_patches = torch.tensor(tquery_patches)\n",
        "    query_labels = torch.tensor(query_labels)\n",
        "\n",
        "    #tsupport_patches = torch.tensor(tsupport_patches)\n",
        "\n",
        "    temp1 = list(zip(tquery_patches, query_labels))\n",
        "    random.shuffle(temp1)\n",
        "\n",
        "    tquery_patches, query_labels = zip(*temp1)\n",
        "\n",
        "    tquery_patches =  torch.reshape(torch.cat(tquery_patches), (C * N, 1000))\n",
        "    tsupport_patches = torch.reshape(torch.cat(tsupport_patches), (C * K, 1000))\n",
        "    tsupport_patches = tsupport_patches.unsqueeze(-1)\n",
        "    tquery_patches = tquery_patches.unsqueeze(-1)\n",
        "\n",
        "    return tquery_patches, tsupport_patches, query_labels, support_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "TbzxfOMXqsVO"
      },
      "outputs": [],
      "source": [
        "def tune_step( support, query, support_labels, query_labels, tK, tC, tN):\n",
        "    #model.train()\n",
        "    support = support.cuda().float()\n",
        "    query = query.cuda().float()\n",
        "    support_labels = torch.tensor(support_labels).cuda().float()\n",
        "    query_labels = torch.tensor(query_labels).cuda().float()\n",
        "\n",
        "    loss, mean_accuracy, mean_predictions = ProtoModel(support, query, support_labels, query_labels, tK, tC, tN, n_times, training=True)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item(), mean_accuracy.item(), mean_predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGKsiSKG1n6K"
      },
      "source": [
        "### tune loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TPWNT6qnzck",
        "outputId": "5d8c1167-1970-45d9-b2ba-e9e793952388"
      },
      "outputs": [],
      "source": [
        "n_episodes = 50\n",
        "\n",
        "for epoch in range(10):\n",
        "    train_loss = 0.0\n",
        "    train_acc = 0.0\n",
        "    for epi in range(n_episodes):\n",
        "      tune_query, tune_support, query_labels, support_labels = tune_episode(test_patches_class_1,5,2,3,test_class_labels)\n",
        "      train_loss_temp , temp_acc , c = tune_step(tune_support, tune_query,support_labels, query_labels, 5, 2, 3)\n",
        "      train_loss += train_loss_temp\n",
        "      train_acc += temp_acc\n",
        "    # Print the training loss and accuracy\n",
        "    print('Epoch {}, Train Loss: {:.3f}, Train Accuracy: {:.3f}'.format(epoch + 1, train_loss/n_episodes, train_acc/n_episodes * 100))\n",
        "    # if (epoch + 1) % 2 == 0:\n",
        "    #   torch.save(ProtoModel.state_dict(), f\"{checkpoint_prefix_1}_epoch_{epoch + 1}.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKAB3lEAOyqc"
      },
      "source": [
        "# load and save torchsharp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "rCRd_iOL0oG2"
      },
      "outputs": [],
      "source": [
        "torch.save(ProtoModel.state_dict(), \"C:/Users/tousi.KCRND/Desktop/tune_weights.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbPJi1Jq1n6K"
      },
      "source": [
        "### load tuning weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPT6RSHuonVc",
        "outputId": "f6334474-c191-452a-c304-73e85317f804"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ProtoModel = Prototypical(model_mobilenet, 1000)\n",
        "loaded_checkpoint = torch.load(\"C:/Users/tousi.KCRND/Desktop/tune_weights.pth\", map_location=torch.device('cpu'))\n",
        "ProtoModel.load_state_dict(loaded_checkpoint)\n",
        "ProtoModel = ProtoModel.to('cpu')\n",
        "n_times = 10\n",
        "next(ProtoModel.parameters()).device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvS-GbDtp2mY"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "46sPp5OMp4HQ"
      },
      "outputs": [],
      "source": [
        "def test_episode(test_patches_class, test_class_labels, test_K):\n",
        "    selected_classes = test_class_labels\n",
        "    support_labels = list(selected_classes)\n",
        "    query_labels = []\n",
        "    support_patches = []\n",
        "    query_patches = []\n",
        "    for x in selected_classes:\n",
        "        y = test_class_labels.index(x)\n",
        "        support_imgs = test_patches_class[y][:test_K,]\n",
        "        query_imgs = test_patches_class[y][test_K:]\n",
        "        support_patches.extend(support_imgs)\n",
        "        query_patches.extend(query_imgs)\n",
        "        for i in range(query_imgs.shape[0]):\n",
        "            query_labels.append(x)\n",
        "\n",
        "    temp1 = list(zip(query_patches, query_labels))\n",
        "    random.shuffle(temp1)\n",
        "    query_patches, query_labels = zip(*temp1)\n",
        "    x = len(query_labels)\n",
        "\n",
        "    query_patches = torch.reshape(torch.cat(query_patches), (x, 1000))\n",
        "    support_patches = torch.reshape(torch.cat(support_patches), (len(support_patches),1000))\n",
        "    support_patches = support_patches.unsqueeze(-1)\n",
        "    query_patches = query_patches.unsqueeze(-1)\n",
        "    #print(type(query_patches))\n",
        "\n",
        "    return query_patches, support_patches, torch.tensor(query_labels),support_labels, x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "xxYyJrIsk8HM"
      },
      "outputs": [],
      "source": [
        "def test_step( support, query, support_labels, query_labels, K, C, N):\n",
        "    model_mobilenet.eval()\n",
        "    with torch.no_grad():\n",
        "        #support = support.cuda()\n",
        "        #query = query.cuda()\n",
        "        #support_labels = support_labels.cuda()\n",
        "        #query_labels = query_labels.cuda()\n",
        "        support = support.float()\n",
        "        query = query.float()\n",
        "        support_labels = torch.tensor(support_labels).float()\n",
        "        query_labels = torch.tensor(query_labels).float()\n",
        "\n",
        "        mc_predictions, mean_accuracy, y = ProtoModel(support, query, support_labels, query_labels, K, C, N, n_times, training=False)\n",
        "\n",
        "    return  mc_predictions, mean_accuracy, y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFxDKrs1jVXU",
        "outputId": "67afd2b3-62dd-4909-cb5d-512c1e3dba0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "[[129  16]\n",
            " [ 13 132]]\n"
          ]
        }
      ],
      "source": [
        "ProtoModel.eval()\n",
        "\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "\n",
        "for epoch in range(1):\n",
        "    test_loss = 0.0\n",
        "    test_acc = 0.0\n",
        "    query_patches, support_patches, query_labels, support_labels, num_queries = test_episode(test_patches_class_2, test_class_labels,5)\n",
        "    mc_predictions, mean_accuracy, y = test_step(support_patches, query_patches, support_labels, query_labels, 5, 2, num_queries/2)\n",
        "\n",
        "    mean_predictions =torch.mean(mc_predictions, axis=0)\n",
        "    class_predictions = torch.argmax(mean_predictions, axis=-1)\n",
        "    class_labels = torch.argmax(y, axis=-1)\n",
        "\n",
        "    # Convert tensors to numpy arrays\n",
        "    class_predictions_np = class_predictions.numpy()\n",
        "    class_labels_np = class_labels.numpy()\n",
        "\n",
        "    # Append predictions and labels to the lists\n",
        "    all_predictions.extend(class_predictions_np)\n",
        "    all_labels.extend(class_labels_np)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "cm = confusion_matrix(all_labels, all_predictions)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1N4f1-ZRyJ8",
        "outputId": "68ba7d50-160d-478e-8223-2abe3223a421"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.89      0.90       145\n",
            "           1       0.89      0.91      0.90       145\n",
            "\n",
            "    accuracy                           0.90       290\n",
            "   macro avg       0.90      0.90      0.90       290\n",
            "weighted avg       0.90      0.90      0.90       290\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(all_labels, all_predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "classes = [' 0', ' 1']\n",
        "\n",
        "# Assuming conf_matrix is your confusion matrix\n",
        "# Assuming classes is a list of class labels\n",
        "\n",
        "# Create a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, cmap='icefire', fmt='g', xticklabels=classes, yticklabels=classes,annot_kws={\"size\": 15})\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.title('Confusion Matrix')\n",
        "\n",
        "# Show plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5eBmrUZ7FWL"
      },
      "source": [
        "# get support from tune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "QYjvSQ8J7H_K"
      },
      "outputs": [],
      "source": [
        "def test_episode_support(test_patches_class, test_class_labels, test_K):\n",
        "    selected_classes = test_class_labels\n",
        "    support_labels = list(selected_classes)\n",
        "    support_patches = []\n",
        "\n",
        "    for x in selected_classes:\n",
        "        y = test_class_labels.index(x)\n",
        "        support_imgs = test_patches_class[y][:test_K,]\n",
        "        support_patches.extend(support_imgs)\n",
        "\n",
        "    support_patches = torch.reshape(torch.cat(support_patches), (len(support_patches), 1000))\n",
        "    support_patches = support_patches.unsqueeze(-1)\n",
        "\n",
        "    return support_patches, torch.tensor(support_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "nbOoTy0A8_On"
      },
      "outputs": [],
      "source": [
        "def test_episode_test(test_patches_class, test_class_labels):\n",
        "    selected_classes = test_class_labels\n",
        "    all_labels = []\n",
        "    all_patches = []\n",
        "\n",
        "    for x in selected_classes:\n",
        "        y = test_class_labels.index(x)\n",
        "        class_imgs = test_patches_class[y]\n",
        "        all_patches.extend(class_imgs)\n",
        "        for i in range(class_imgs.shape[0]):\n",
        "            all_labels.append(x)\n",
        "\n",
        "    temp1 = list(zip(all_patches, all_labels))\n",
        "    random.shuffle(temp1)\n",
        "    all_patches, all_labels = zip(*temp1)\n",
        "    x = len(all_labels)\n",
        "\n",
        "    all_patches = torch.reshape(torch.cat(all_patches), (x, 1000))\n",
        "    all_patches = all_patches.unsqueeze(-1)\n",
        "\n",
        "    return all_patches, torch.tensor(all_labels) , x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K48K6qnQ7mHm",
        "outputId": "3b2400f7-0af8-4af4-f614-9831f715188f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "[[134  16]\n",
            " [ 11 139]]\n"
          ]
        }
      ],
      "source": [
        "ProtoModel.eval()\n",
        "\n",
        "all_predictions = []\n",
        "all_labels = []\n",
        "\n",
        "for epoch in range(1):\n",
        "    test_loss = 0.0\n",
        "    test_acc = 0.0\n",
        "    support_patches, support_labels = test_episode_support(test_patches_class_1, test_class_labels,10)\n",
        "    query_patches, query_labels, num_queries = test_episode_test(test_patches_class_2, test_class_labels)\n",
        "    mc_predictions, mean_accuracy, y = test_step(support_patches, query_patches, support_labels, query_labels, 10, 2, num_queries/2)\n",
        "\n",
        "    mean_predictions =torch.mean(mc_predictions, axis=0)\n",
        "    class_predictions = torch.argmax(mean_predictions, axis=-1)\n",
        "    class_labels = torch.argmax(y, axis=-1)\n",
        "\n",
        "    class_predictions_np = class_predictions.numpy()\n",
        "    class_labels_np = class_labels.numpy()\n",
        "\n",
        "    all_predictions.extend(class_predictions_np)\n",
        "    all_labels.extend(class_labels_np)\n",
        "    \n",
        "cm = confusion_matrix(all_labels, all_predictions)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeQq9ni58Qjc",
        "outputId": "39fef4fb-1456-4ad5-d646-35195598fcd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.89      0.91       150\n",
            "           1       0.90      0.93      0.91       150\n",
            "\n",
            "    accuracy                           0.91       300\n",
            "   macro avg       0.91      0.91      0.91       300\n",
            "weighted avg       0.91      0.91      0.91       300\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(all_labels, all_predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "classes = [' 0', ' 1']\n",
        "\n",
        "# Assuming conf_matrix is your confusion matrix\n",
        "# Assuming classes is a list of class labels\n",
        "\n",
        "# Create a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, cmap='Greens', fmt='g', xticklabels=classes, yticklabels=classes,annot_kws={\"size\": 15})\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.title('Confusion Matrix')\n",
        "\n",
        "# Show plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwksKmRJtOu8"
      },
      "source": [
        "### Create prototype with support data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sdxWdzPBkGW"
      },
      "outputs": [],
      "source": [
        "support_patches, support_labels = test_episode_support(test_patches_class_1, test_class_labels,10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-DbGgVRuurL"
      },
      "outputs": [],
      "source": [
        "def calc_prototype(support, support_labels, K, C):\n",
        "    n_class = C\n",
        "    n_support = K\n",
        "\n",
        "    tsupport_patches, _ = test_episode_support(support, support_labels, K)\n",
        "    #tsupport_labels = support_labels.repeat(K)\n",
        "    cat = tsupport_patches.float()\n",
        "    z = model_mobilenet(cat)\n",
        "    z_prototypes = z[:n_class * n_support].view(n_class, n_support, z.shape[-1])\n",
        "    z_prototypes = torch.mean(z_prototypes, dim=1)\n",
        "    return z_prototypes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWvPcnhguzDD"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "def save_to_json_new(filename, *arrays):\n",
        "    json_data = [arr.tolist() for arr in arrays]\n",
        "    with open(filename, 'w') as json_file:\n",
        "        json.dump(json_data, json_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5oM4tvdt-ev"
      },
      "outputs": [],
      "source": [
        "tsupport_patches, _ = test_episode_support(test_patches_class_1, test_class_labels, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4V2MwezTtwpF",
        "outputId": "4132199f-eae5-4cdc-e57b-36e463f7b3d6"
      },
      "outputs": [],
      "source": [
        "prototype_test = calc_prototype(test_patches_class_1, test_class_labels, 10, 2)\n",
        "prototype_test[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TUPtARlulvZ"
      },
      "outputs": [],
      "source": [
        "proto0_tensor_reshaped = prototype_test[0].unsqueeze(0)\n",
        "proto1_tensor_reshaped = prototype_test[1].unsqueeze(0)\n",
        "\n",
        "\n",
        "d0_squared = calc_euclidean_dists(model_mobilenet(torch.ones(1000)), proto0_tensor_reshaped).item()\n",
        "d1_squared = calc_euclidean_dists(model_mobilenet(torch.ones(1000)), proto1_tensor_reshaped).item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEtcDK38vEXM",
        "outputId": "b8c57939-a40f-4e95-8a4a-cc98872650f8"
      },
      "outputs": [],
      "source": [
        "print('d0_squared', d0_squared)\n",
        "print('d1_squared', d1_squared)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUxqsL7gvOPj"
      },
      "outputs": [],
      "source": [
        "d0_squared_ = (torch.linalg.vector_norm(model_mobilenet(torch.ones(1000)) - proto0_tensor_reshaped).item()**2)/64\n",
        "d1_squared_ = (torch.linalg.vector_norm(model_mobilenet(torch.ones(1000)) - proto1_tensor_reshaped).item()**2)/64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3aeUxpVvY9V",
        "outputId": "bf061423-ecc9-4767-a574-a3a78e1257bb"
      },
      "outputs": [],
      "source": [
        "print('d0_squared_:', d0_squared_)\n",
        "print('d1_squared_:', d1_squared_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxRMFObaODPm",
        "outputId": "175d28ec-915a-4a62-b264-b65da5f43f0c"
      },
      "outputs": [],
      "source": [
        "print(\"Model Output Shape:\", model_mobilenet(torch.ones(1000)).shape)\n",
        "print(\"Proto0 Tensor Shape:\", proto0_tensor_reshaped.shape)\n",
        "print(\"Proto1 Tensor Shape:\", proto1_tensor_reshaped.shape)\n",
        "\n",
        "d0_squared = calc_euclidean_dists(model_mobilenet(torch.ones(1000)), proto0_tensor_reshaped).item()\n",
        "d1_squared = calc_euclidean_dists(model_mobilenet(torch.ones(1000)), proto1_tensor_reshaped).item()\n",
        "\n",
        "print(\"D0 Squared (calc_euclidean_dists):\", d0_squared)\n",
        "print(\"D1 Squared (calc_euclidean_dists):\", d1_squared)\n",
        "\n",
        "d0_squared_ = (torch.linalg.vector_norm(model_mobilenet(torch.ones(1000)) - proto0_tensor_reshaped).item()**2)/64\n",
        "d1_squared_ = (torch.linalg.vector_norm(model_mobilenet(torch.ones(1000)) - proto1_tensor_reshaped).item()**2)/64\n",
        "\n",
        "print(\"D0 Squared (torch.linalg.vector_norm):\", d0_squared_)\n",
        "print(\"D1 Squared (torch.linalg.vector_norm):\", d1_squared_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMH02uYyu2az"
      },
      "outputs": [],
      "source": [
        "model_mobilenet.eval()\n",
        "num_iterations = 10\n",
        "results_0 = []\n",
        "results_1 = []\n",
        "\n",
        "#shot_value = [10]\n",
        "shot_value = [3, 5, 7, 10, 15, 20, 25 , 30, 40]\n",
        "iteration_prototypes = []\n",
        "for value in shot_value:\n",
        "    prototype = calc_prototype(test_patches_class_1, test_class_labels, value, 2)\n",
        "    iteration_prototypes.append(prototype)\n",
        "\n",
        "results_0.append([proto[0].detach().numpy() for proto in iteration_prototypes])\n",
        "results_1.append([proto[1].detach().numpy() for proto in iteration_prototypes])\n",
        "\n",
        "\n",
        "del shot_value\n",
        "del iteration_prototypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qPoAqZrvfgo"
      },
      "outputs": [],
      "source": [
        "def convert_to_serializable(obj):\n",
        "    if isinstance(obj, np.ndarray):\n",
        "        return obj.tolist()\n",
        "    elif isinstance(obj, list):\n",
        "        return [convert_to_serializable(item) for item in obj]\n",
        "    else:\n",
        "        return obj\n",
        "\n",
        "result_0_flat = [item for sublist in results_0 for item in sublist]\n",
        "result_0_array = np.array(result_0_flat)\n",
        "result_0_list = result_0_array.tolist()\n",
        "converted_result_0 = convert_to_serializable(result_0_list)\n",
        "\n",
        "result_1_flat = [item for sublist in results_1 for item in sublist]\n",
        "result_1_array = np.array(result_1_flat)\n",
        "result_1_list = result_1_array.tolist()\n",
        "converted_result_1 = convert_to_serializable(result_1_list)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_WC_oQgTILm"
      },
      "source": [
        "# test prototype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QY9xvuiq0RBf"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "with open('new_prototype_0.json', 'w') as json_file:\n",
        "    json.dump(converted_result_0, json_file)\n",
        "\n",
        "with open('new_prototype_1.json', 'w') as json_file:\n",
        "    json.dump(converted_result_1, json_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tg1loAiyTFf-"
      },
      "outputs": [],
      "source": [
        "c_test = pd.read_csv('/content/test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVAMe8GjTtkv"
      },
      "outputs": [],
      "source": [
        "def read_all_rows_from_csv(file_path):\n",
        "    df = pd.read_csv(file_path, header=None, skiprows=1)\n",
        "   # df = df.iloc[:, :-1]\n",
        "    all_samples = df.values.tolist()\n",
        "    return all_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tuw2GK72aaZJ"
      },
      "outputs": [],
      "source": [
        "json_file_path_0 = '/content/new_prototype_0.json'\n",
        "json_file_path_1 = '/content/new_prototype_1.json'\n",
        "\n",
        "with open(json_file_path_0, 'r') as json_file_0:\n",
        "    proto0 = json.load(json_file_0)\n",
        "\n",
        "with open(json_file_path_1, 'r') as json_file_1:\n",
        "    proto1 = json.load(json_file_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1YzzePsvTx-Z"
      },
      "outputs": [],
      "source": [
        "csv_file_path = \"/content/test.csv\"\n",
        "all_samples = read_all_rows_from_csv(csv_file_path)\n",
        "\n",
        "model_mobilenet.eval()\n",
        "\n",
        "sample_size = 1\n",
        "\n",
        "all_results = []\n",
        "\n",
        "for input_sample in all_samples:\n",
        "    tests = []\n",
        "\n",
        "    for sample_index in range(sample_size):\n",
        "\n",
        "        proto0_tensor = torch.tensor(proto0[sample_index])\n",
        "        proto1_tensor = torch.tensor(proto1[sample_index])\n",
        "        proto0_tensor_reshaped = proto0_tensor.unsqueeze(0)\n",
        "        proto1_tensor_reshaped = proto1_tensor.unsqueeze(0)\n",
        "\n",
        "        t_input = torch.tensor([float(value) for value in input_sample], dtype=torch.float32)\n",
        "        t_input = t_input.detach()\n",
        "        #print('t_input_shape',t_input.shape)\n",
        "\n",
        "        # d0 = torch.linalg.norm(model_mobilenet(t_input) - proto0_tensor).item()\n",
        "        # d1 = torch.linalg.norm(model_mobilenet(t_input) - proto1_tensor).item()\n",
        "\n",
        "        d0_squared = calc_euclidean_dists(model_mobilenet(t_input), proto0_tensor_reshaped).item()\n",
        "        d1_squared = calc_euclidean_dists(model_mobilenet(t_input), proto1_tensor_reshaped).item()\n",
        "        d0 = d0_squared\n",
        "        d1 = d1_squared\n",
        "        # print('d0:',d0)\n",
        "        # print('d1:',d1)\n",
        "        # print('*****************')\n",
        "\n",
        "        if d0 < d1:\n",
        "            tests.append(0)\n",
        "        elif d1 <= d0:\n",
        "            tests.append(1)\n",
        "\n",
        "    majority_vote = 1 if sum(tests) > (sample_size/2) else 0\n",
        "    sample_results =  tests+   [majority_vote]\n",
        "    all_results.append(sample_results)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "-yBeXMEbPoqk"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
